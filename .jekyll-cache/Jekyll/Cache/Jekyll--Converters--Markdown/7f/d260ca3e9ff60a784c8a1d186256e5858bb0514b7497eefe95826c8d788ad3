I"e<h2 id="graph-pooling">Graph Pooling</h2>

<ul>
  <li>Global Pooling : summarize graph into fixed-size representation<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image1.png" alt="global pooling" /></li>
  <li>Hierarchical Pooling : Learn hierarchical representation<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image2.png" alt="hierarchical pooling" /></li>
</ul>

<h3 id="global-pooling">Global Pooling</h3>

<ul>
  <li>Simple Readout : Average / Max / Min / â€¦<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image3.png" alt="simple readout" /></li>
  <li>Neural Networks for Readout : GG-NN / Set2Set / SortPool<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image4.png" alt="nn for readout" /><br />
SortPool ì€ ê° node ì— ëŒ€í•´ feature ë³„ë¡œ sorting í•œ í›„ ëª‡ ê°œì˜ node ë§Œ ì„ íƒí•˜ëŠ” ë°©ë²•</li>
</ul>

<h3 id="hierarchical-pooling">Hierarchical Pooling</h3>

<ul>
  <li>DiffPool(Differentiable Pooling) : softly assign node from bottom to higher<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image5.png" alt="diffpool" /></li>
  <li>gPool(Graph Pooling)<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image6.png" alt="gpool" /></li>
  <li>SAGPool(Self-Attention Graph Pooling)<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image7.png" alt="sagpool" />
    <ul>
      <li>ì—¬ê¸°ì„œ $\tilde{A} \in \mathbb{R}^{N\times N}$ ëŠ” Adjacency matrix</li>
      <li>$\tilde{D} \in \mathbb{R}^{N\times N}$ ëŠ” degree matrix of $\tilde{A}$</li>
      <li>$X \in \mathbb{R}^{N\times F}$ ëŠ” N ê°œì˜ node ì˜ F dimensional feature ë¥¼ ê°€ì§„ input graph feature</li>
      <li>SAGPool ì—ì„œ parameter ëŠ” $\Theta_{att} \in \mathbb{R}^{F \times 1}$ ë¿ì´ë‹¤.</li>
      <li>pooling ê²°ê³¼ëŠ” graph feature ì™€ topology ì— ê¸°ë°˜í•˜ë©°, graph convolution ì„ ì´ìš©í•´ self-attention score ë¥¼ ì–»ëŠ”ë‹¤.</li>
      <li>node selection method ì€ ë‹¤ì–‘í•œ í¬ê¸°ì™€ êµ¬ì¡°ì˜ ì…ë ¥ì— ëŒ€í•´ì„œë„ ì…ë ¥ ê·¸ë˜í”„ì˜ ë…¸ë“œ ì¼ë¶€ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ í•¨.</li>
      <li></li>
    </ul>
  </li>
  <li>EdgePool<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image8.png" alt="edgepool" /></li>
</ul>

<h2 id="scene-graph-learning">Scene graph learning</h2>

<p><img src="/assets/images/2019-12-14---graph-neural-networks-2/image9.png" alt="scene graph learning pipeline" /></p>

<p>Visual relationships of an image as a graph :<br />
Predicate detection &lt;=&gt; Object detection</p>

<p>Multi-relational tensor ë¥¼ ì‚¬ìš©í•¨.<br />
[[Object, Predicate, Object ]] ë¡œ ìŒì„ ë§Œë“¤ì–´ ëƒ„</p>

<p>Ground Truth ë¥¼ ì–´ë–»ê²Œ í•´ì•¼í•˜ëŠ”ì§€ì— ëŒ€í•œ ê³ ë¯¼ì´ ë§ì´ í•„ìš”í•˜ë‹¤.<br />
(ì´ë ‡ê²Œ ì €ë ‡ê²Œ ì—¬ëŸ¬ê°€ì§€ ë°©í–¥ìœ¼ë¡œ í•´ì„ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ)</p>

<h2 id="graph-transformer-networksgtn">Graph Transformer Networks(GTN)</h2>

<ul>
  <li>
    <p>Spatial Transformer Networks<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image10.png" alt="spatial transformer network" /></p>
  </li>
  <li>
    <p>meta-path : multi-hop ê´€ê³„ë¥¼ ìƒˆë¡œìš´ path ë¡œ ë³´ê³  ìƒˆë¡­ê²Œ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆê²Œ í•¨.<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image11.png" alt="meta path" /></p>
  </li>
  <li>
    <p>graph transformer layer : learn a soft selection of edge types and composite relations for generating useful multi-hop connections(meta-paths)<br />
<img src="/assets/images/2019-12-14---graph-neural-networks-2/image12.png" alt="graph transformer layer" />
ìœ„ì˜ ì˜ˆì œëŠ” 2-hop relationship ì„ ë³´ê³  ìˆëŠ” ê²ƒì´ë‹¤. ë§ˆì§€ë§‰ì—ëŠ” meta-path ë§Œ ë‚˜íƒ€ë‚œë‹¤.</p>
  </li>
</ul>

<p>ì´ ë•Œ, meta-path ì˜ ê¸¸ì´ê°€ ëŠ˜ì–´ë‚  ìˆ˜ë¡(hop ì´ ë§ì•„ì§ˆ ìˆ˜ë¡) ë¬¸ì œì ì´ ë°œìƒí•  ìˆ˜ ìˆë‹¤.</p>

<blockquote>
  <p>ê²½ë¡œê°€ ì¤‘ë³µì´ ë˜ëŠ” ë¬¸ì œì¼ê¹Œ?</p>
</blockquote>
:ET